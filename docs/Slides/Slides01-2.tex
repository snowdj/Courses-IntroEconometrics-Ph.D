%%!TEX TS-program = latex

%This template gives a nice gray-sober environment. 
\documentclass[red,handout]{beamer}
\usepackage{etex}
\usepackage[utf8]{inputenc}
\input ../AuxFiles/PreambleSlides.tex
 
\title{{\scshape Econometrics I}}
\author{{\scshape Jos\'e Luis Montiel Olea}}
\date{}





%---------------------------------------------------Begin Document-------------------------------------
\begin{document}
\setbeamerfont{alerted text}{series=\normalfont}
\setbeamercolor{alerted text}{fg=blue}

\frame{\titlepage}


\frame{
\begin{center}
Introduction to Probability and Statistics for Economists \\
(Ph.D. in Economics, 1st year)
\end{center}
}



\frame{
\begin{center}
\textbf{Lectures 1 and 2} 
\end{center}
}

\section{Introduction}

\frame{
\frametitle{\normalsize \scshape Two Main Blocks}
\justifying
\begin{enumerate}
\item \alt<2>{\textcolor{blue}{{\scshape Probability Theory}}}{{\scshape Probability Theory}} \\
\vspace{.3cm}
\begin{center}\invisible<1-2>{\textcolor{blue}{Basic tools to model uncertainty}}
\end{center}
\vspace{.2cm}
\item \alt<4>{\textcolor{blue}{{\scshape Mathematical Statistics}}}{{\scshape Mathematical Statistics }} \\
\vspace{.3cm}
\begin{center}
\invisible<1-4>{\textcolor{blue}{Data $\rightarrow$ Decisions}}
\end{center}
\only<5>{}
\end{enumerate}
}

\section{Probability Space/Random Variables}

\frame{
\begin{center}
\textbf{Probability Theory}
\end{center}
\begin{center}
How to model `randomness'?
\end{center}
}


\frame{
\frametitle{\normalsize {\scshape Things we will learn in Lecture 1:}}
\begin{itemize} [<alert@+>]
\item [$\star$] What is a probability space? \vspace{.4cm}
\begin{enumerate}
\item What is measurable space? \vspace{.3cm}
\item What is a probability space? \vspace{.4cm}
\end{enumerate}
\item [$\star$] What is a random variable? \vspace{.4cm}
\item [$\star$] What is the `distribution’ or `law’ of a random variable? 
\end{itemize}
}

\frame{
\begin{center}
\textbf{What is a probability space?}
\end{center}
$$(\Omega, \mathcal{F}, \prob)  $$
}

\frame{
\frametitle{\normalsize {\scshape Probability Space: Two components}}
$$(\Omega, \mathcal{F}, \prob)  $$
\begin{enumerate} [<+- | alert@+>]
\item $(\Omega, \mathcal{F})$ measurable space. 
\item [] $$\Omega: \textrm{ States of the world}, \quad \mathcal{F}: \textrm{ Set of events } (\subseteq \Omega).$$
\vspace{.1cm}
\item $\prob: \mathcal{F} \rightarrow [0,1].$ Probability Measure
\item [] $$\text{`How likely is an event in $\mathcal{F}$'}$$ 
\end{enumerate}
}

\frame{
\frametitle{\normalsize \caps{Measurable Space}}
\begin{center}
See notes. 
\end{center}
}


\frame{
\frametitle{\normalsize {\scshape Probability Measures}} 
\begin{enumerate} [<+-|alert@+>]
\item [$\star$] $\prob(\phi)=0, \: \prob(\Omega)=1$ (Normalization) \\ \vspace{.5cm}
\item [$\star$] For any finite collection $A_1, A_2, \ldots A_m$ such that $A_i \cap A_j = \emptyset$

$$\prob\Big( \cup_{i=1}^{m} A_i \Big) = \sum_{i=1}^{m} \prob(A_i) $$
\item [] This property is called \textcolor{blue}{additivity}. \vspace{.3cm}
\item [$\star$] If you replace finite by \emph{countably infinite}, Property 2 is called \textcolor{blue}{$\sigma$-additivity}.
\end{enumerate}
}

\frame{
\frametitle{\normalsize {\scshape Important}}
\begin{center}
\textcolor{blue}{Normalization and $\sigma$-additivity \underline{define} a probability measure}
\end{center}
}





\frame{
\begin{center}
\textbf{What is a random variable?}
\end{center}
$$ X: \Omega \rightarrow S$$
}



\frame{
\frametitle{\normalsize {\scshape Random Variable}}
$$\textcolor{blue}{X: \Omega \rightarrow S} $$ \pause
\begin{enumerate}[<+- | alert@+>]
\item[$\star$] $\Omega:$ Set of states of the world.\\ \vspace{.5cm}
\item[$\star$] $S:$ Image Space
\vspace{.5cm}
\item[$\star$] $X:$ Random Variable \vspace{.5cm}
\end{enumerate}
}



\frame{
\begin{center}
\textbf{What is the distribution or law of a random variable?} 
\end{center}
}



\frame{
\frametitle{\normalsize {\scshape `Induced’ Probability of a Random Variable}}
\begin{enumerate}
\item [$\star$]  \alt<2>{\textcolor{blue}{The probability $\prob$ on $\Omega$ induces a probability on subsets of $S$:}}{The probability $\prob$ on $\Omega$ induces a probability on subsets of $S$:}

$$\prob_{X} [F]  \equiv \prob [ \: \{\omega \: | \: X(\omega) \in F \} \:  ], \quad F \subseteq S $$ \vspace{.2cm}

\item [$\star$] \alt<3>{\textcolor{blue}{How likely are the states of the world in which F occurs?}} {How likely are the states of the world in which F occurs?} 
\end{enumerate}
}


\frame{
\begin{center}
\textcolor{blue}{The induced probability of a random variable is usually called its {\scshape Distribution or Law}}
\end{center}
}



\frame{
\begin{center}
\textcolor{blue}{Different random variables can induce the same probability on $S$.}
\end{center}
}

\frame{
\frametitle{\normalsize \alt<2>{$P_{X_2}(1)=.5$}{$P_{X_1}(1)=.5$}}
\begin{center}
\begin{pspicture*}(-4,-4) (4,4) 
\psaxes[ticks=none, labels=none]{->}(-3,-3)(-3,-3)(3,3)
\uput[25](3.5,-3.4){\footnotesize $\Omega$}
\uput[25](-3.3,-3.4){\footnotesize $0$}
\uput[25](2.5,-3.4){\footnotesize $1$}
\uput[25](-3.7,3.2){\footnotesize $S=\{0,1\}$}
\only<1>{\psline[linecolor=red, linewidth=.1] (-3,2)(-.2,2)}
\only<1>{\psline[linecolor=red, linewidth=.1] (-.2,-3)(3,-3)}
\uput[25](-.4,-3.4){\footnotesize $0.5$}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize \alt<2>{$P_{X_2}(1)=.5$}{$P_{X_1}(1)=.5$}}
\begin{center}
\begin{pspicture*}(-4,-4) (4,4) 
\psaxes[ticks=none, labels=none]{->}(-3,-3)(-3,-3)(3,3)
\uput[25](3.5,-3.4){\footnotesize $\Omega$}
\uput[25](-3.3,-3.4){\footnotesize $0$}
\uput[25](2.5,-3.4){\footnotesize $1$}
\uput[25](-3.7,3.2){\footnotesize $S=\{0,1\}$}
\only<1>{\psline[linecolor=blue, linewidth=.1] (-3,-3)(-.2,-3)}
\only<1>{\psline[linecolor=blue, linewidth=.1] (-.2,2)(3,2)}
\uput[25](-.4,-3.4){\footnotesize $0.5$}
\end{pspicture*} 
\end{center}
}

\section{C.D.F.}

\frame{
\begin{center}
\textbf{The Cumulative Distribution Function of Real-valued Random Variables }
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape c.d.f of an $\R$-valued random variable}}
\begin{enumerate}
\item [$\star$] \alt<2>{\textcolor{blue}{How likely is a realization of the random variable X below x?}}{How likely is a realization of the random variable X below x?} \vspace{.3cm}

\item [$\star$] \alt<3>{\textcolor{blue}{The c.d.f. summarizes this information}}{The c.d.f. summarizes this information} 
$$F_{X}: \R \rightarrow [0,1] $$

$$F_{X}(x) \equiv \prob\Big\{ \omega \in \Omega \: | \: X(\omega) \leq x \Big\} $$
\end{enumerate}
}


\frame{
\begin{center}
\textbf{Examples of c.d.f.}\\
\hyperlink{Uniform-cdf}{\beamergotobutton{Uniform distribution}}\\
\hyperlink{Bernoulli-cdf}{\beamergotobutton{Bernoulli distribution}} \\
\hyperlink{Properties}{\beamerskipbutton{Skip to Properties}}
\end{center}
}

\frame{
\label{Uniform-cdf}
$$F_{X}(x) = 
\left \{
\begin{array}{ccc}
0  & \text{if}  & x < a   \\
& &\\
(x-a)/b-a &  \text{if} & x \in [a,b)  \\
 & &\\
 1 & \text{if}  & x \geq b   
\end{array}
\right.
 $$

}


\frame{
\frametitle{\normalsize \alt<2>{\scshape Uniform Distribution on $[a,b]$}{c.d.f. of  $X(\omega)=a + \omega [b-a]$}}
\begin{center}
\begin{pspicture*}(-4,-4) (4,4) 
\psaxes[ticks=none, labels=none]{->}(0,-3)(-4,-3)(4,3)
\uput[25](3.5,-3.4){\footnotesize $\R$}
\uput[25](-.3,-3.4){\footnotesize $0$}
\uput[25](-.5,-1){\footnotesize $1$}
\uput[25](-.5,3.2){\footnotesize $F_X(\cdot)$}
\psline[linecolor=blue, linewidth=.1] (-4,-3)(-1,-3)
\psline[linecolor=blue, linewidth=.1] (1,-1)(4,-1)
\psPolynomial[coeff=-2 1, linewidth=.1, linecolor=blue]{-1}{1}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $X(\omega)=a + \omega [b-a]$}
\begin{center}
\begin{pspicture*}(-4,-4) (4,4) 
\psaxes[ticks=none, labels=none]{->}(-3,-3)(-3,-3)(3,3)
\uput[25](3.5,-3.4){\footnotesize $\Omega$}
\uput[25](-3.3,-3.4){\footnotesize $0$}
\uput[25](2.5,-3.4){\footnotesize $1$}
\uput[25](-3.7,3.2){\footnotesize $S=\R$}
\uput[25](-3.7,-3){\footnotesize $a$}
\uput[25](-3.7,2.8){\footnotesize $b$}
\psPolynomial[coeff=0 1,linecolor=red]{-3}{2.8}
\end{pspicture*} 
\end{center}
}



\frame{
\label{Bernoulli-cdf}
$$F_{X}(x) = 
\left \{
\begin{array}{ccc}
0  & \text{if}  & x < 0   \\
& &\\
1-p &  \text{if} & x \in [0,1)  \\
 & &\\
 1 & \text{if}  & x \geq 1  
\end{array}
\right.
 $$
}


\frame{
\frametitle{\normalsize \alt<2>{{\scshape Bernoulli Distribution with parameter $p$}}{c.d.f. of  $X(\omega)=\mathbf{1}[\omega \geq 1-p ]$}}
\begin{center}
\begin{pspicture*}(-4,-4) (4,4) 
\psaxes[ticks=none, labels=none]{->}(0,-3)(-4,-3)(4,3)
\uput[25](3.5,-3.4){\footnotesize $\R$}
\uput[25](-.3,-3.4){\footnotesize $0$}
\uput[25](-.5,-1){\footnotesize $1$}
\uput[25](2,-3.4){\footnotesize $1$}
\uput[25](-1,-2.7){\footnotesize $1-p$}
\uput[25](-.5,3.2){\footnotesize $F_X(\cdot)$}
\psline[linecolor=blue, linewidth=.1] (-4,-3)(0,-3)
\psline[linecolor=blue, linewidth=.1] (0,-2.5)(2.25,-2.5)
\psline[linecolor=blue, linewidth=.1] (2.25,-1)(4,-1)
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $X(\omega) = \mathbf{1}[\omega \geq 1-p ]$ }


\begin{center}
\begin{pspicture*}(-4,-4) (4,4) 
\psaxes[ticks=none, labels=none]{->}(-3,-3)(-3,-3)(3,3)
\uput[25](3.5,-3.4){\footnotesize $\Omega$}
\uput[25](-3.3,-3.4){\footnotesize $0$}
\uput[25](2.5,-3.4){\footnotesize $1$}
\uput[25](-3.7,3.2){\footnotesize $S=\R$}
\psline[linecolor=red] (-3,-3)(-2,-3)
\psline[linecolor=red] (-2,2)(3,2)
\uput[25](-2.3,-3.4){\footnotesize $1-p$}

\end{pspicture*} 
\end{center}
}


\frame{
\label{Properties}
\begin{center}
\textbf{What are the common properties of c.d.f?}
\end{center}
}


\frame{
\frametitle{\normalsize {\scshape Characterization}}

\begin{enumerate}
\item $F_{X}$ is non-decreasing \vspace{.3cm}
\item $\lim_{x \rightarrow \infty} F_{X}(x) =1$ \vspace{.3cm}
\item $\lim_{x \rightarrow -\infty} F_{X}(x) =0$ \vspace{.3cm}
\item $\lim_{h \rightarrow 0^{+}} F_{X}(x+h) = F_{X}(x)$ \vspace{.3cm} \pause
\end{enumerate}
\begin{center}
\item [] \textcolor{blue}{In fact, these 4 properties characterize the induced c.d.f. of a real-valued random variable!}
\end{center}
}



\section{Discrete/Continuous Type}

\frame{
\begin{center}
\textbf{Discrete and Continuous Type of Real-Valued Random Variables}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Discrete Distributions / Discrete r.v.s }} 
{\scshape Distribution:} Disributions for which 
$\exists$ a countable set 
$$\text{Supp}=\{x_1, x_2, \ldots\}, x_i \in \R,$$ 
such that \vspace{.3cm}
\begin{enumerate}[a)] 
\item $\prob_{X}(X=x_i)>0 \quad \forall \quad x_i \in \text{Supp}$ \vspace{.2cm}
\item  $\sum_{x_i \in \text{Supp}} \prob_{X}(X=x_i) = 1$
\end{enumerate} \vspace{.3cm}
are called \textcolor{blue}{discrete}. 
}

\frame{
\frametitle{\normalsize {\scshape p.m.f.}}
\begin{center}
\alt<2>{\textcolor{blue}{We will identify discrete distributions/r.v.s by its support and its p.m.f.}}{The function $\prob_{X}(X=x_i)$ is called the \textcolor{blue}{Probability Mass Function} (p.m.f.)}
\end{center}
}


\frame{
\frametitle{\normalsize {\scshape (Absolutely) Continuous Distributions}}
Random Variables for which
$$ \textcolor{blue}{ F_X(x) = \int_{-\infty}^{x} f(z) dz   }  $$
\noindent for some $f(z) \geq 0$ $\forall z \in \R$ are called: \pause \vspace{.3cm}
\begin{center}
\textcolor{blue}{(Absolutely) Continuous} \pause
\end{center} 
The function $f(z)$ is called \pause \vspace{.3cm}
\begin{center}
\textcolor{blue}{Probability Density Function (p.d.f.)} 
\end{center}
}

\frame{
\begin{center}
\begin{center}
\textcolor{blue}{We will identify continuous distributions/r.v.s by its p.d.f.}
\end{center}
\end{center}
}

\frame{
\begin{center}
The set
$$\{z \in \R \: | \: f(z) > 0 \} \subseteq \R $$
is called the \textcolor{blue}{support} of the continuous r.v. \vspace{.5cm}
\end{center}
}


\frame{
\frametitle{\normalsize {\scshape From p.d.f. to probabilities}}
Let $X$ be a real-valued random variable with p.d.f. $f(z)$ \pause \vspace{.5cm}
\begin{itemize}  [<+->]
\item [$\star$] \alert<2>{$\prob_{X}[X \leq a] = \int_{-\infty}^{a} f(z) dz$} \vspace{.5cm}
\item [$\star$] \alert<3>{$\prob_{X}[a \leq X \leq b] = \int_{a}^{b} f(z) dz$} \vspace{.5cm} 
\item [$\star$] \alert<4>{$\prob_{X}[X > a ] = \int_{a}^{\infty} f(z) dz$} 
\end{itemize}
}





\frame{
\label{Examples-Discrete}
\begin{center}
\textbf{Examples of (Univariate) Discrete Distributions}\\
\vspace{.2cm}
\hyperlink{Bernoulli}{\beamergotobutton{Bernoulli}}
\hyperlink{Binomial}{\beamergotobutton{Binomial}} \\
\hyperlink{Examples-Continuous}{\beamerskipbutton{Skip to Continuous Distributions}}
\end{center}
}


\frame{
\label{Bernoulli}
\frametitle{\normalsize {\scshape Bernoulli Distribution $(p)$,  $p \in (0,1)$}}
\begin{itemize}
\item [$\star$] The Bernoulli distribution with parameters $p$ has support:
$$\text{Supp}=\{0, 1\} $$ \pause
and p.m.f. given by: \pause
$$\prob_{X}(X=x)=p^{x} (1-p)^{1-x} \quad x \in \{0,1\}$$
\end{itemize}
}

\frame{
\frametitle{\normalsize {\scshape How do we know it is a p.m.f.?}}
Two parts: \vspace{.3cm}
\begin{enumerate}[a)]
\item $\prob_{X}(X=x)>0 \quad \forall \: x \in \{0,1\}$. Easy to verify:
$$\textcolor{blue}{p^{x} (1-p)^{1-x}>0}$$ \pause
\item 
$$\sum_{x \in \{0,1\}} p^{x} (1-p)^{1-x} = (1-p) + p$$
\end{enumerate}
\hyperlink{Examples-Discrete}{\beamerreturnbutton{Examples}}
}


\frame{
\label{Binomial}
\frametitle{\normalsize {\scshape Binomial Distribution $(n,p)$, $n \in \mathbb{N}, p \in (0,1)$}}
\begin{itemize}
\item [$\star$] The binomial distribution with parameters $(n,p)$ has support:
$$\text{Supp}=\{0,1, 2, \ldots n\} $$ \pause
and p.m.f. given by: \pause
$$\prob_{X}(X=x) \equiv \frac{n!}{(n-x)! x!} p^{x} (1-p)^{n-x} \quad x \in \text{Supp}$$
\end{itemize}
}

\frame{
\frametitle{\normalsize {\scshape How do we know it is a p.m.f.?}}
Two parts: \vspace{.3cm}
\begin{enumerate}[a)]
\item $\prob_{X}(X=x)>0 \quad \forall \: x \in \{0,1,2, \ldots n\}$. Easy to verify:
$$\textcolor{blue}{\frac{n!}{(n-x)! x!} p^{x} (1-p)^{n-x}>0}$$ \pause
\item 
$$\sum_{x \in \{0,1, \ldots n\}} \frac{n!}{(n-x)! x!} p^{x} (1-p)^{n-x} =1 ?$$
\end{enumerate}
}

\frame{
\frametitle{\normalsize {\scshape How do we know it is a p.m.f.?}}
Use the Binomial Theorem
$$(a+b)^n = \sum_{x \in \{0,1, \ldots n\}} \frac{n!}{(n-x)! x!} a^{x} b^{n-x} =1$$ \pause
$$a=p, \quad b=1-p $$
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(3,.1)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(0,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(4,0)
\uput[-90](4,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{3}{0.1}
\end{pspicture}
\end{center}
}


\frame{
\frametitle{\normalsize {\scshape Binomial $(3,.3)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(4,0)
\uput[-90](4,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{3}{0.3}
\end{pspicture}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(3,.5)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(4,0)
\uput[-90](4,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{3}{0.5}
\end{pspicture}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(3,.7)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(4,0)
\uput[-90](4,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{3}{0.7}
\end{pspicture}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(3,.9)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(4,0)
\uput[-90](4,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{3}{0.9}
\end{pspicture}
\end{center}
}


\frame{
\frametitle{\normalsize {\scshape Binomial $(5,.1)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(6,0)
\uput[-90](6,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{5}{0.1}
\end{pspicture}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(5,.3)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(6,0)
\uput[-90](6,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{5}{0.3}
\end{pspicture}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(5,.5)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(6,0)
\uput[-90](6,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{5}{0.5}
\end{pspicture}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(5,.7)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(6,0)
\uput[-90](6,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{5}{0.7}
\end{pspicture}
\end{center}
}

\frame{
\frametitle{\normalsize {\scshape Binomial $(5,.9)$ }}
\begin{center}
\psset{xunit=1cm,yunit=5cm}
\begin{pspicture}(-1,.5)(7,0.55)
\psaxes[Dy=0.2,dy=0.2\psyunit]{->}(0,0)(-.5,0)(6,0)
\uput[-90](6,0){$\text{Supp}$} \uput[90](0,0.5){}
\psBinomial[markZeros,printValue,fillstyle=vlines]{5}{0.9}
\end{pspicture}
\end{center}
}

\frame{
\begin{center}
\hyperlink{Examples-Discrete}{\beamerreturnbutton{Examples}}
\end{center}
}


\frame{
\label{Examples-Continuous}
\begin{center}
\textbf{Examples of (Univariate) Continuous Distributions}\\
\hyperlink{Uniform}{\beamergotobutton{Uniform}}
\hyperlink{Normal}{\beamergotobutton{Normal}} \\
\hyperlink{Moments}{\beamerskipbutton{Skip to Moments}}
\end{center}
}

\frame{
\label{Uniform}
\frametitle{\normalsize {\scshape Uniform [a,b]}}
\begin{itemize}
\item [$\star$] The uniform distribution with parameters $[a,b]$ has p.d.f. 
$$f(z)=\frac{1}{b-a} \mathbf{1}\{z \in [a,b]\}$$ \pause 
\item [$\star$] and support $[a,b]$
\end{itemize}
}

\frame{
\frametitle{\normalsize \scshape p.d.f. of the Uniform Distribution on $[a,b]$ }
\begin{center}
\begin{pspicture*}(-4,-4) (4,4) 
\psaxes[ticks=none, labels=none]{->}(0,-3)(-4,-3)(4,1.3)
\uput[25](-3.5,2){\footnotesize $f(z) = 
\left \{
\begin{array}{ccc}
0  & \text{if}  & z < a   \\
& &\\
1/(b-a) &  \text{if} & z \in [a,b]  \\
 & &\\
 0 & \text{if}  & z > b   
\end{array}
\right.
 $}
\uput[25](3.5,-3.4){\footnotesize $\R$}
\uput[25](-.3,-3.4){\footnotesize $0$}
\uput[25](-1.2,-3.4){\footnotesize $a$}
\uput[25](.8,-3.4){\footnotesize $b$}
\uput[25](1.2,-1.1){\footnotesize $1/(b-a)$}
\psline[linecolor=blue, linewidth=.1] (-4,-3)(-1,-3)
\psline[linecolor=blue, linewidth=.1] (1,-3)(4,-3)
\psPolynomial[coeff=-1 0, linewidth=.1, linecolor=blue]{-1}{1}
\end{pspicture*} 
\end{center}
}

\frame{
\label{Normal}
\frametitle{\normalsize {\scshape Normal Distribution $(\mu, \sigma^2)$}}
\begin{itemize}
\item [$\star$] The normal distribution with parameters $(\mu, \sigma^2)$ has p.d.f. 
$$f(z)=\frac{1}{\sigma \sqrt{2 \pi}} \exp\Big( -\frac{1}{2 \sigma^2} (z-\mu)^2 \Big)$$ \pause 
\item [$\star$] and support $\R$
\end{itemize}
}

\frame{
\frametitle{\normalsize {\scshape Normal Distribution $(\mu, \sigma^2)$}}
\begin{itemize}
\item [$\star$] $f(z)> 0 \pause \checkmark$ \pause \vspace{.5cm}
\item [$\star$] How do we know that:
$$ \int_{-\infty}^{\infty} \frac{1}{\sigma \sqrt{2 \pi}} \exp\Big( -\frac{1}{2 \sigma^2} (z-\mu)^2 \Big) = 1? $$ \pause
\textcolor{blue}{Euler-Poisson Integral/Gaussian Integral} 
\end{itemize}
}


\frame{
\frametitle{\normalsize $N(0,1)$}
\begin{center}
\psset{yunit=4cm,xunit=2}
\begin{pspicture*}(-2,-.25) (2,1.25) 
\uput[25](-.25,.5){\footnotesize $.5$}
\uput[25](-2,-.2){\footnotesize $-4$}
\uput[25](1.8,-.2){\footnotesize $4$}
\psaxes[ticks=none, labels=none]{->}(0,0)(-2.5,0)(2.5,1.25)
\psGauss[mue=0, sigma=1, linecolor=red, linewidth=2pt]{-2}{2}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $N(0,.5)$}
\begin{center}
\psset{yunit=4cm,xunit=2}
\begin{pspicture*}(-2,-.25) (2,1.25) 
\uput[25](-.25,.5){\footnotesize $.5$}
\uput[25](-2,-.2){\footnotesize $-4$}
\uput[25](1.8,-.2){\footnotesize $4$}
\psaxes[ticks=none, labels=none]{->}(0,0)(-2.5,0)(2.5,1.25)
\psGauss[mue=0, sigma=.5, linecolor=red, linewidth=2pt]{-2}{2}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $N(0,.35)$}
\begin{center}
\psset{yunit=4cm,xunit=2}
\begin{pspicture*}(-2,-.25) (2,1.25) 
\uput[25](-.25,.5){\footnotesize $.5$}
\uput[25](-2,-.2){\footnotesize $-4$}
\uput[25](1.8,-.2){\footnotesize $4$}
\psaxes[ticks=none, labels=none]{->}(0,0)(-2.5,0)(2.5,1.25)
\psGauss[mue=0, sigma=.35, linecolor=red, linewidth=2pt]{-2}{2}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $N(.5,.35)$}
\begin{center}
\psset{yunit=4cm,xunit=2}
\begin{pspicture*}(-2,-.25) (2,1.25) 
\uput[25](-.25,.5){\footnotesize $.5$}
\uput[25](-2,-.2){\footnotesize $-4$}
\uput[25](1.8,-.2){\footnotesize $4$}
\psaxes[ticks=none, labels=none]{->}(0,0)(-2.5,0)(2.5,1.25)
\psGauss[mue=.5, sigma=.35, linecolor=red, linewidth=2pt]{-2}{2}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $N(-5,.35)$}
\begin{center}
\psset{yunit=4cm,xunit=2}
\begin{pspicture*}(-2,-.25) (2,1.25) 
\uput[25](-.25,.5){\footnotesize $.5$}
\uput[25](-2,-.2){\footnotesize $-4$}
\uput[25](1.8,-.2){\footnotesize $4$}
\psaxes[ticks=none, labels=none]{->}(0,0)(-2.5,0)(2.5,1.25)
\psGauss[mue=-.5, sigma=.35, linecolor=red, linewidth=2pt]{-2}{2}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $N(0,.35)$}
\begin{center}
\psset{yunit=4cm,xunit=2}
\begin{pspicture*}(-2,-.25) (2,1.25) 
\uput[25](-.25,.5){\footnotesize $.5$}
\uput[25](-2,-.2){\footnotesize $-4$}
\uput[25](1.8,-.2){\footnotesize $4$}
\psaxes[ticks=none, labels=none]{->}(0,0)(-2.5,0)(2.5,1.25)
\psGauss[mue=0, sigma=.35, linecolor=red, linewidth=2pt]{-2}{2}
\end{pspicture*} 
\end{center}
}

\frame{
\frametitle{\normalsize $\textbf{N(0,1)}$}
\begin{center}
\psset{yunit=4cm,xunit=2}
\begin{pspicture*}(-2,-.25) (2,1.25) 
\uput[25](-.25,.5){\footnotesize $.5$}
\uput[25](-2,-.2){\footnotesize $-4$}
\uput[25](1.8,-.2){\footnotesize $4$}
\psaxes[ticks=none, labels=none]{->}(0,0)(-2.5,0)(2.5,1.25)
\psGauss[mue=0, sigma=1, linecolor=red, linewidth=2pt]{-2}{2}
\end{pspicture*} 
\end{center}
}

\section{Moments}




\frame{
\label{Moments}
\begin{center}
\textbf{Moments}
\end{center}
}

\frame{
\frametitle{\normalsize \scshape{Mean of a discrete r.v.}}
\begin{itemize}[<+-|alert@+>]
\item [$\star$] {Let $X$ be a discrete r.v. with support $S$ and p.m.f. $\prob_{X}$} \vspace{.3cm}
\item [$\star$] {The mean or expected value of $X$ is defined as:}
$$\expec_{\prob_{X}}[X] \equiv \mu \equiv \sum_{x_n \in S} x_n \: \prob_{X}[X = x_n ] $$ 
\item [$\star$] {The variance of $X$ is defined as:}
$$\expec_{\prob_{X}}[(X-\mu)^2] \equiv \sigma^2 \equiv \sum_{x_n \in S} (x_n-\mu)^2 \: \prob_{X}[X = x_n ] $$ 

\end{itemize}
}

\frame{ 
\frametitle{\normalsize {\scshape Mean of a Continuous Type r.v.}}
\begin{itemize} [<+->] 
\item [$\star$] For a continuous-type random variable $g(X)$, where $X \sim f_X$:
\alert<2>{$$\expec_{f_X}[g(X)] \equiv \int_{-\infty}^{\infty} g(z) f_X(z) dz $$}
\item [$\star$] Therefore, the mean and the variance of X are given by:
\begin{eqnarray*}
\mu &=& \int_{-\infty}^{\infty} z f_X(z)dz \\
\sigma^2 &=& \int_{-\infty}^{\infty} (z-\mu)^2 f_X(z) dz
\end{eqnarray*}
\end{itemize}
}


\frame{
\begin{center}
\textbf{Examples}\\
\hyperlink{Mean-Uniform}{\beamergotobutton{Mean of a Uniform [a,b]}} \\
\hyperlink{Variance-Uniform}{\beamergotobutton{Second Moment of a Uniform [a,b]}}\\
\hyperlink{MGF}{\beamerskipbutton{Skip to Moment Generating Function}}
\end{center}
}

\frame{
\label{Mean-Uniform}
\frametitle{\normalsize {\scshape U[a,b]}: $\mu$}
\begin{itemize}
\item [$\star$] $\mu = \frac{b+a}{2}$ \vspace{.3cm}
\item [$\star$] $f(z)=\frac{1}{b-a} \mathbf{1}\{z \in [a,b]\}$ \vspace{.3cm}
\item [$\star$] Derivation:
\begin{eqnarray*}
\mu = \int_{-\infty}^{\infty} z f(z) dz  &=& \frac{1}{b-a}\int_{a}^{b} z dz \\ \pause
&=& \frac{1}{2}\frac{1}{b-a} z^2 \Big]_{a}^{b} \\ \pause
&=& \frac{1}{2} \frac{1}{b-a} (b^2-a^2) \\ \pause
&=& \frac{b+a}{2}
\end{eqnarray*}
\end{itemize}
}

\frame{
\label{Variance-Uniform}
\frametitle{\normalsize {\scshape U[a,b]}: $\mathbb{E}[X^2]$}
\begin{itemize}
\item [$\star$] $\mathbb{E}[X^2] = \frac{b^2 + ab + a^2}{3}$ \vspace{.3cm}
\item [$\star$] Derivation: 
\begin{eqnarray*}
\expec[X^2] = \int_{-\infty}^{\infty} z^2 f(z) dz  &=& \frac{1}{b-a}\int_{a}^{b} z^2 dz \\ \pause
&=& \frac{1}{3}\frac{1}{b-a} z^3 \Big]_{a}^{b} \\ \pause
&=& \frac{1}{3} \frac{1}{b-a} (b^3-a^3) \\ \pause
&=& \frac{b^2 + ab + a^2}{3}
\end{eqnarray*}
\end{itemize}
}

\frame{
\noindent Hence, $\sigma^2$ is given by:
$$ \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \frac{b^2 + ab + a^2}{3} - \frac{b^2 + 2ab + a^2}{4} = \frac{(b-a)^2}{12} $$
}


\frame{
\label{MGF}
\begin{center}
\textbf{Moment Generating Function}
\end{center}
}


\frame{
\frametitle{\normalsize \caps{MGF}}
\begin{itemize}[<+-|alert@+>]
\justifying
\item [$\star$] The $\mathbb{R}$-valued r.v. $X$ has moment generating function $m_{X}(\cdot)$ if
$$ m_{x}(t) \equiv E_{F}\Big[\exp \Big( t X \Big)\Big] < \infty, \quad \forall \: t \in (-\epsilon,\epsilon).$$
\item [$\star$] The k-th moment of $X$ is the $k$-th derivative of $m_{x}(t)$ at $t=0$. 
\end{itemize}
}

\frame{
\frametitle{\normalsize \caps{Example}}
\begin{itemize}[<+-|alert@+>]
\item [$\star$] $X \sim \text{Bernoulli}(p)$
\item [] 
\begin{eqnarray*}
m_{X}(t) &=& E_{F}\Big[\exp \Big( t X \Big)\Big]  \\
&=& p \exp(t) + (1-p) \exp(0) \\
\end{eqnarray*}
\item [$\star$] Moments:
\item [] $ E_{F}[X]= p$ \\
\item [] $E_{F}[X^2] = p $ \\
\item [] $\vdots$
\item [] $E_{F}[X^k]=p$
\end{itemize}
}

\end{document}